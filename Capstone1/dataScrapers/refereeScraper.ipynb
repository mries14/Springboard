{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: The final, cleaned script is in the last cell in this workbook.\n",
    " # The majority of cells are scrap code that led me to the final cell's script\n",
    "\n",
    "import csv\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.pro-football-reference.com/officials/HittMa0r.htm', 'https://www.pro-football-reference.com/officials/BostBy0r.htm', 'https://www.pro-football-reference.com/officials/PagaCa0r.htm', 'https://www.pro-football-reference.com/officials/PagaPe0r.htm', 'https://www.pro-football-reference.com/officials/AndeWa0r.htm', 'https://www.pro-football-reference.com/officials/CheeBo0r.htm', 'https://www.pro-football-reference.com/officials/MorePe0r.htm', 'https://www.pro-football-reference.com/officials/BergJe0r.htm', 'https://www.pro-football-reference.com/officials/ArthGa0r.htm', 'https://www.pro-football-reference.com/officials/EdwaSc0r.htm']\n"
     ]
    }
   ],
   "source": [
    "# Our first step is to collect the referee links for every referee in the nfl\n",
    "# each individual referee comes in link form: https://www.pro-football-reference.com/officials/HittMa0r.htm\n",
    "refLinks = []\n",
    "\n",
    "url = 'https://www.pro-football-reference.com/officials/'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "links = soup.select(\"tbody tr th a\")\n",
    "for a in links:\n",
    "    refLinks.append('https://www.pro-football-reference.com'+ str(a[\"href\"]))\n",
    "\n",
    "#in the above code, td.right.gamelink a is a CSS selector which matches\n",
    "#all a elements inside td elements with classes of right and gamelink.\n",
    "\n",
    "print(refLinks[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup our csv\n",
    "csvFile = open(\"./csvFiles/refereeData2.csv\", 'w+')\n",
    "writer = csv.writer(csvFile)\n",
    "writer.writerow(('gameId','date','refId','refName','position','homeTeam','homeScore','homePenalties','homePenyds','awayTeam','awayScore','awayPenalties','awayPenyds','totalScore'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that we have all needed links, we will collect all needed data from each link\n",
    "# First, let's create a function that grabs the nexessary data from an individual link: getData()\n",
    "\n",
    "def getData(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "    refName = soup.find('h1',{'itemprop':'name'}).text\n",
    "    refId = url\n",
    "    \n",
    "    refereeDataComment = soup.find('div',{'id':'all_games'}).find(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "    refereeDataComment = BeautifulSoup(refereeDataComment, \"html5lib\")\n",
    "\n",
    "    allRows = refereeDataComment.find('tbody').find_all('tr',{'class':None})\n",
    "\n",
    "    for row in allRows:\n",
    "        cellList = []\n",
    "        for cell in row:\n",
    "            cellList.append(cell.text)\n",
    "\n",
    "   \n",
    "        gameId = row.select('th a')[0]['href'][-16:-4]\n",
    "        date = cellList[0]\n",
    "        homeTeam = cellList[1]\n",
    "        awayTeam = cellList[2]\n",
    "        position = cellList[3]\n",
    "        awayScore = cellList[4]\n",
    "        awayPenalties = cellList[5]\n",
    "        awayPenyds = cellList[6]\n",
    "        homeScore = cellList[7]\n",
    "        homePenalties = cellList[8]\n",
    "        homePenyds = cellList[9]\n",
    "        totalScore = int(awayScore) + int(homeScore)\n",
    "\n",
    "        writer.writerow((gameId,date,refId,refName,position,homeTeam,homeScore,homePenalties,homePenyds,awayTeam,awayScore,awayPenalties,awayPenyds,totalScore))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for link in refLinks:\n",
    "    getData(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.pro-football-reference.com/officials/ArthGa0r.htm'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "refName = soup.find('h1',{'itemprop':'name'}).text\n",
    "refId = url\n",
    "\n",
    "refereeDataComment = soup.find('div',{'id':'all_games'}).find(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "refereeDataComment = BeautifulSoup(refereeDataComment, \"html5lib\")\n",
    "\n",
    "allRows = refereeDataComment.find('tbody').find_all('tr',{'class':None})\n",
    "\n",
    "for row in allRows[:5]:\n",
    "    cellList = []\n",
    "    for cell in row:\n",
    "        cellList.append(cell.text)\n",
    "        \n",
    "    gameId = row.select('th a')[0]['href'][-16:-4]\n",
    "    date = cellList[0]\n",
    "    homeTeam = cellList[1]\n",
    "    awayTeam = cellList[2]\n",
    "    position = cellList[3]\n",
    "    awayScore = cellList[4]\n",
    "    awayPenalties = cellList[5]\n",
    "    awayPenyds = cellList[6]\n",
    "    homeScore = cellList[7]\n",
    "    homePenalties = cellList[8]\n",
    "    homePenyds = cellList[9]\n",
    "    totalScore = int(awayScore) + int(homeScore)\n",
    "        \n",
    "    #writer.writerow((gameId,date,refId,refName,position,homeTeam,homeScore,homePenalties,homePenyds,awayTeam,awayScore,awayPenalties,awayPenyds,totalScore))\n",
    "#     print(gameId)\n",
    "#     print(date)\n",
    "#     print(refName)\n",
    "#     print(position)\n",
    "#     print(homeTeam)\n",
    "#     print(homeScore)\n",
    "#     print(homePenalties)\n",
    "#     print(homePenyds)\n",
    "#     print(awayTeam)\n",
    "#     print(awayScore)\n",
    "#     print(awayPenalties)\n",
    "#     print(awayPenyds)\n",
    "#     print(totalScore)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "September 19, 1999\n",
      "September 26, 1999\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.pro-football-reference.com/officials/ArthGa0r.htm'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "\n",
    "refereeDataComment = soup.find('div',{'id':'all_games'}).find(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "refereeDataComment = BeautifulSoup(refereeDataComment, \"html5lib\")\n",
    "\n",
    "allRows = refereeDataComment.find('tbody').find_all('tr',{'class':None})\n",
    "\n",
    "for row in allRows[:2]:\n",
    "    cellList = []\n",
    "    for cell in row:\n",
    "        cellList.append(cell.text)\n",
    "\n",
    "    date = cellList[0]\n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gary Arthur\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.pro-football-reference.com/officials/ArthGa0r.htm'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "refName = soup.find('h1',{'itemprop':'name'}).text\n",
    "print(refName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-34f425a52155>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrefLinks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mgetData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-109-34f425a52155>\u001b[0m in \u001b[0;36mgetData\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mtotalScore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mawayScore\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhomeScore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgameId\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrefId\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrefName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhomeTeam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhomeScore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhomePenalties\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhomePenyds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mawayTeam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mawayScore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mawayPenalties\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mawayPenyds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotalScore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrefLinks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied"
     ]
    }
   ],
   "source": [
    "# Final cleaned script\n",
    "import csv\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import requests\n",
    "\n",
    "\n",
    "refLinks = []\n",
    "\n",
    "url = 'https://www.pro-football-reference.com/officials/'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "links = soup.select(\"tbody tr th a\")\n",
    "for a in links:\n",
    "    refLinks.append('https://www.pro-football-reference.com'+ str(a[\"href\"]))\n",
    "    \n",
    "csvFile = open(\"./csvFiles/refereeData3.csv\", 'w+')\n",
    "writer = csv.writer(csvFile)\n",
    "writer.writerow(('gameId','date','refId','refName','position','homeTeam','homeScore','homePenalties','homePenyds','awayTeam','awayScore','awayPenalties','awayPenyds','totalScore'))\n",
    "\n",
    "def getData(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "    refName = soup.find('h1',{'itemprop':'name'}).text\n",
    "    refId = url\n",
    "    \n",
    "    refereeDataComment = soup.find('div',{'id':'all_games'}).find(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "    refereeDataComment = BeautifulSoup(refereeDataComment, \"html5lib\")\n",
    "\n",
    "    allRows = refereeDataComment.find('tbody').find_all('tr',{'class':None})\n",
    "\n",
    "    for row in allRows:\n",
    "        cellList = []\n",
    "        for cell in row:\n",
    "            cellList.append(cell.text)\n",
    "\n",
    "   \n",
    "        gameId = row.select('th a')[0]['href'][-16:-4]\n",
    "        date = cellList[0]\n",
    "        homeTeam = cellList[1]\n",
    "        awayTeam = cellList[2]\n",
    "        position = cellList[3]\n",
    "        awayScore = cellList[4]\n",
    "        awayPenalties = cellList[5]\n",
    "        awayPenyds = cellList[6]\n",
    "        homeScore = cellList[7]\n",
    "        homePenalties = cellList[8]\n",
    "        homePenyds = cellList[9]\n",
    "        totalScore = int(awayScore) + int(homeScore)\n",
    "\n",
    "        writer.writerow((gameId,date,refId,refName,position,homeTeam,homeScore,homePenalties,homePenyds,awayTeam,awayScore,awayPenalties,awayPenyds,totalScore))\n",
    "\n",
    "for link in refLinks:\n",
    "    getData(link)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
